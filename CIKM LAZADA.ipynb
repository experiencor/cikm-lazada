{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:44:14.531926Z",
     "start_time": "2017-05-08T22:44:13.686407+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from BeautifulSoup import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "def write_submission(filename, predicted_results):\n",
    "    if not os.path.exists('submission'):\n",
    "        os.makedirs('submission')\n",
    "    np.savetxt('submission/' + filename, predicted_results, fmt='%.5f')\n",
    "    print(filename + ' updated!')\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "word_parser = RegexpTokenizer('[A-Za-z]+', flags=re.UNICODE)\n",
    "digit_checker = re.compile(\"\\d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:44:14.951066Z",
     "start_time": "2017-05-08T22:44:14.740951+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(filepath_or_buffer='data/training/data_train.csv', \n",
    "                 names=['country','sku_id','title','category_lvl_1','category_lvl_2','category_lvl_3','short_description','price','product_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:44:15.937471Z",
     "start_time": "2017-05-08T22:44:15.897498+08:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>title</th>\n",
       "      <th>category_lvl_1</th>\n",
       "      <th>category_lvl_2</th>\n",
       "      <th>category_lvl_3</th>\n",
       "      <th>short_description</th>\n",
       "      <th>price</th>\n",
       "      <th>product_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my</td>\n",
       "      <td>AD674FAASTLXANMY</td>\n",
       "      <td>Adana Gallery Suri Square Hijab – Light Pink</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>Women</td>\n",
       "      <td>Muslim Wear</td>\n",
       "      <td>&lt;ul&gt;&lt;li&gt;Material : Non sheer shimmer chiffon&lt;/...</td>\n",
       "      <td>49.00</td>\n",
       "      <td>local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my</td>\n",
       "      <td>AE068HBAA3RPRDANMY</td>\n",
       "      <td>Cuba Heartbreaker Eau De Parfum Spray 100ml/3.3oz</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>Bath &amp; Body</td>\n",
       "      <td>Hand &amp; Foot Care</td>\n",
       "      <td>Formulated with oil-free hydrating botanicals/...</td>\n",
       "      <td>128.00</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my</td>\n",
       "      <td>AN680ELAA9VN57ANMY</td>\n",
       "      <td>Andoer 150cm Cellphone Smartphone Mini Dual-He...</td>\n",
       "      <td>TV, Audio / Video, Gaming &amp; Wearables</td>\n",
       "      <td>Audio</td>\n",
       "      <td>Live Sound &amp; Stage</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;150cm mini microphone compatible for ...</td>\n",
       "      <td>25.07</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my</td>\n",
       "      <td>AN957HBAAAHDF4ANMY</td>\n",
       "      <td>ANMYNA Complaint Silky Set 柔顺洗发配套 (Shampoo 520...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>Hair Care</td>\n",
       "      <td>Shampoos &amp; Conditioners</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;ANMYNA Complaint Silky Set (Shampoo 5...</td>\n",
       "      <td>118.00</td>\n",
       "      <td>local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my</td>\n",
       "      <td>AR511HBAXNWAANMY</td>\n",
       "      <td>Argital Argiltubo Green Clay For Face and Body...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>Men's Care</td>\n",
       "      <td>Body and Skin Care</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;100% Authentic&lt;/li&gt; &lt;li&gt;Rrefresh and ...</td>\n",
       "      <td>114.80</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country              sku_id  \\\n",
       "0      my    AD674FAASTLXANMY   \n",
       "1      my  AE068HBAA3RPRDANMY   \n",
       "2      my  AN680ELAA9VN57ANMY   \n",
       "3      my  AN957HBAAAHDF4ANMY   \n",
       "4      my    AR511HBAXNWAANMY   \n",
       "\n",
       "                                               title  \\\n",
       "0       Adana Gallery Suri Square Hijab – Light Pink   \n",
       "1  Cuba Heartbreaker Eau De Parfum Spray 100ml/3.3oz   \n",
       "2  Andoer 150cm Cellphone Smartphone Mini Dual-He...   \n",
       "3  ANMYNA Complaint Silky Set 柔顺洗发配套 (Shampoo 520...   \n",
       "4  Argital Argiltubo Green Clay For Face and Body...   \n",
       "\n",
       "                          category_lvl_1 category_lvl_2  \\\n",
       "0                                Fashion          Women   \n",
       "1                        Health & Beauty    Bath & Body   \n",
       "2  TV, Audio / Video, Gaming & Wearables          Audio   \n",
       "3                        Health & Beauty      Hair Care   \n",
       "4                        Health & Beauty     Men's Care   \n",
       "\n",
       "            category_lvl_3                                  short_description  \\\n",
       "0              Muslim Wear  <ul><li>Material : Non sheer shimmer chiffon</...   \n",
       "1         Hand & Foot Care  Formulated with oil-free hydrating botanicals/...   \n",
       "2       Live Sound & Stage  <ul> <li>150cm mini microphone compatible for ...   \n",
       "3  Shampoos & Conditioners  <ul> <li>ANMYNA Complaint Silky Set (Shampoo 5...   \n",
       "4       Body and Skin Care  <ul> <li>100% Authentic</li> <li>Rrefresh and ...   \n",
       "\n",
       "    price   product_type  \n",
       "0   49.00          local  \n",
       "1  128.00  international  \n",
       "2   25.07  international  \n",
       "3  118.00          local  \n",
       "4  114.80  international  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:44:23.868554Z",
     "start_time": "2017-05-08T22:44:23.780337+08:00"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_description(description):\n",
    "    description = BeautifulSoup(description)\n",
    "    description = description.getText(' ')\n",
    "    \n",
    "    tokens = word_parser.tokenize(description)\n",
    "    \n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    tokens = list(filter(lambda t: t not in stop, tokens))\n",
    "    tokens = list(filter(lambda t: t not in punctuation, tokens))\n",
    "    tokens = list(filter(lambda t: t not in [u'x'], tokens))\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def tokenize_title(title):\n",
    "    try:\n",
    "        title = ''.join(i for i in title if ord(i)<128)\n",
    "        tokens_ = [word_tokenize(sent) for sent in sent_tokenize(title)]\n",
    "        \n",
    "        tokens = []\n",
    "        for token_by_sent in tokens_:\n",
    "            tokens += token_by_sent\n",
    "\n",
    "        tokens = list(filter(lambda t: t.lower() not in stop, tokens))\n",
    "        tokens = list(filter(lambda t: t not in punctuation, tokens))\n",
    "        tokens = list(filter(lambda t: t not in [u\"'s\", u\"n't\", u\"...\", u\"''\", u'``', u'\\u2014', u'\\u2026', u'\\u2013'], tokens))\n",
    "        \n",
    "        filtered_tokens = []\n",
    "        for token in tokens:\n",
    "            if re.search('[a-zA-Z]', token):\n",
    "                filtered_tokens.append(token)\n",
    "\n",
    "        filtered_tokens = list(map(lambda token: token.lower(), filtered_tokens))\n",
    "\n",
    "        return filtered_tokens\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "def extract_title_features(titles):\n",
    "    title_features = np.zeros((len(titles),3))\n",
    "    \n",
    "    for index in xrange(len(titles)):\n",
    "        title = titles[index]\n",
    "        \n",
    "        # Check if title contains non-ascii characters\n",
    "        try:\n",
    "            title.decode('ascii')\n",
    "        except:\n",
    "            title_features[index,0] = 1.\n",
    "            \n",
    "        # Compute the number of tokens title contains\n",
    "        tokens = tokenize_title(title)\n",
    "        title_features[index,1] = len(title)\n",
    "        \n",
    "        # Check if title contains a number\n",
    "        if digit_checker.search(title):\n",
    "            title_features[index,2] = 1.\n",
    "    \n",
    "    return title_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:44:52.052564Z",
     "start_time": "2017-05-08T22:44:25.754571+08:00"
    }
   },
   "outputs": [],
   "source": [
    "# PERFOM tf-idf ON DESCRIPTIONS\n",
    "tf_idf_desription = TfidfVectorizer(min_df=10, max_features=10000, tokenizer=tokenize_description, ngram_range=(1, 2))\n",
    "\n",
    "descriptions = df_train['short_description'].replace(np.nan, '')\n",
    "descriptions = tf_idf_desription.fit_transform(list(descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:45:09.699238Z",
     "start_time": "2017-05-08T22:44:52.056759+08:00"
    }
   },
   "outputs": [],
   "source": [
    "# PERFOM tf-idf ON TITLE\n",
    "tf_idf_title = TfidfVectorizer(min_df=10, max_features=10000, tokenizer=tokenize_title, ngram_range=(1, 2))\n",
    "\n",
    "titles = tf_idf_title.fit_transform(list(df_train['title']))\n",
    "df_train['tokenized_title'] = df_train['title'].map(tokenize_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:34:38.546800Z",
     "start_time": "2017-05-08T22:34:38.530339+08:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: Adana Gallery Suri Square Hijab – Light Pink\n",
      "tokens: ['adana', 'gallery', 'suri', 'square', 'hijab', 'light', 'pink']\n",
      "\n",
      "title: Cuba Heartbreaker Eau De Parfum Spray 100ml/3.3oz\n",
      "tokens: ['cuba', 'heartbreaker', 'eau', 'de', 'parfum', 'spray', '100ml/3.3oz']\n",
      "\n",
      "title: Andoer 150cm Cellphone Smartphone Mini Dual-Headed Omni-Directional Mic Microphone with Collar Clip for iPad iPhone5 6s 6 Plus Smartphones\n",
      "tokens: ['andoer', '150cm', 'cellphone', 'smartphone', 'mini', 'dual-headed', 'omni-directional', 'mic', 'microphone', 'collar', 'clip', 'ipad', 'iphone5', '6s', 'plus', 'smartphones']\n",
      "\n",
      "title: ANMYNA Complaint Silky Set 柔顺洗发配套 (Shampoo 520ml + Conditioner 250ml)\n",
      "tokens: ['anmyna', 'complaint', 'silky', 'set', 'shampoo', '520ml', 'conditioner', '250ml']\n",
      "\n",
      "title: Argital Argiltubo Green Clay For Face and Body 250ml\n",
      "tokens: ['argital', 'argiltubo', 'green', 'clay', 'face', 'body', '250ml']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check tokenization for first 5 listings\n",
    "for title, tokens in zip(df_train['title'].head(5), df_train['tokenized_title'].head(5)):\n",
    "    print 'title:', title\n",
    "    print'tokens:', tokens\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:45:18.566434Z",
     "start_time": "2017-05-08T22:45:09.702500+08:00"
    }
   },
   "outputs": [],
   "source": [
    "# Extract other features of titles\n",
    "title_features = extract_title_features(df_train['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:45:21.739212Z",
     "start_time": "2017-05-08T22:45:18.568332+08:00"
    }
   },
   "outputs": [],
   "source": [
    "# CONSTRUCT INPUTS AND OUTPUTS\n",
    "X = np.concatenate([titles.toarray(),\n",
    "                    title_features,\n",
    "                    descriptions.toarray(),\n",
    "                    pd.get_dummies(df_train['category_lvl_1']).as_matrix(), \n",
    "                    pd.get_dummies(df_train['category_lvl_2']).as_matrix(),\n",
    "                    pd.get_dummies(df_train['category_lvl_3']).as_matrix(),\n",
    "                    pd.get_dummies(df_train['product_type']).as_matrix(),\n",
    "                    df_train['price'].as_matrix().reshape(-1,1),\n",
    "                    (df_train.product_type == 'local').as_matrix().astype(float).reshape(-1,1)\n",
    "                   ], \n",
    "                   axis=1)\n",
    "\n",
    "y = pd.read_csv(\"data/training/clarity_train.labels\", header=None).as_matrix().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:45:23.524366Z",
     "start_time": "2017-05-08T22:45:21.740846+08:00"
    }
   },
   "outputs": [],
   "source": [
    "# SPLIT INTO TRAINING SET AND VALIDATION SET\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:45:26.301031Z",
     "start_time": "2017-05-08T22:45:23.526003+08:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RMSE: 0.211910\n"
     ]
    }
   ],
   "source": [
    "# TRAIN AND EVALUATE THE MODEL\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model RMSE: %f\" % mean_squared_error(model.predict_proba(X_test)[:,1], y_test)**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:45:29.969640Z",
     "start_time": "2017-05-08T22:45:29.867981+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv(filepath_or_buffer='data/validation/data_valid.csv', \n",
    "                       names=['country','sku_id','title','category_lvl_1','category_lvl_2','category_lvl_3','short_description','price','product_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:45:38.441523Z",
     "start_time": "2017-05-08T22:45:30.881325+08:00"
    }
   },
   "outputs": [],
   "source": [
    "# PERFOM tf-idf ON DESCRIPTIONS\n",
    "descriptions = df_valid['short_description'].replace(np.nan, '')\n",
    "descriptions = tf_idf_desription.transform(list(descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:45:44.036825Z",
     "start_time": "2017-05-08T22:45:38.443205+08:00"
    }
   },
   "outputs": [],
   "source": [
    "# PERFOM tf-idf ON TITLE\n",
    "titles = tf_idf_title.transform(list(df_valid['title']))\n",
    "df_valid['tokenized_title'] = df_valid['title'].map(tokenize_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:45:46.842833Z",
     "start_time": "2017-05-08T22:45:44.038650+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract other features of titles\n",
    "title_features = extract_title_features(df_valid['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:45:47.755179Z",
     "start_time": "2017-05-08T22:45:46.845196+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONSTRUCT INPUTS AND OUTPUTS\n",
    "X_valid = np.concatenate([titles.toarray(),\n",
    "                          title_features,\n",
    "                          descriptions.toarray(),\n",
    "                          pd.get_dummies(df_valid['category_lvl_1']).as_matrix(), \n",
    "                          pd.get_dummies(df_valid['category_lvl_2']).as_matrix(),\n",
    "                          pd.get_dummies(df_valid['category_lvl_3']).as_matrix(),\n",
    "                          pd.get_dummies(df_valid['product_type']).as_matrix(),\n",
    "                          df_valid['price'].as_matrix().reshape(-1,1),\n",
    "                          (df_valid.product_type == 'local').as_matrix().astype(float).reshape(-1,1)\n",
    "                         ], \n",
    "                         axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:45:51.544916Z",
     "start_time": "2017-05-08T22:45:48.289916+08:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clarity_valid.predict updated!\n"
     ]
    }
   ],
   "source": [
    "# RETRAIN THE MODEL ON THE WHOLE DATASET\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "predicted_results = model.predict_proba(X_valid)[:, 1]\n",
    "write_submission('clarity_valid.predict', predicted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Conciseness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:45:56.261771Z",
     "start_time": "2017-05-08T22:45:56.248029+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONSTRUCT INPUTS AND OUTPUTS\n",
    "y = pd.read_csv(\"data/training/conciseness_train.labels\", header=None).as_matrix().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:46:01.056340Z",
     "start_time": "2017-05-08T22:45:57.961984+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SPLIT INTO TRAINING SET AND VALIDATION SET\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:46:05.076582Z",
     "start_time": "2017-05-08T22:46:02.087149+08:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RMSE: 0.354889\n"
     ]
    }
   ],
   "source": [
    "# TRAIN AND EVALUATE THE MODEL\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model RMSE: %f\" % mean_squared_error(model.predict_proba(X_test)[:,1], y_test)**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:46:20.286070Z",
     "start_time": "2017-05-08T22:46:17.829701+08:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conciseness_valid.predict updated!\n"
     ]
    }
   ],
   "source": [
    "# RETRAIN THE MODEL ON THE WHOLE DATASET\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "predicted_results = model.predict_proba(X_valid)[:, 1]\n",
    "write_submission('conciseness_valid.predict', predicted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-08T14:46:26.303204Z",
     "start_time": "2017-05-08T22:46:25.889100+08:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('zip -j submission submission/*')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "67px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
